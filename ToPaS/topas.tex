%Формат файла
\documentclass[12pt]{article} 
\usepackage[paperheight=297mm,
   paperwidth=210mm,
   top=20mm,
   bottom=20mm,
   left=15mm,
   right=15mm]{geometry}


%Текст
\usepackage[fontsize=12pt]{fontsize}
\usepackage[russian]{babel}
\usepackage{color}
\usepackage{transparent}
\usepackage{amsthm}
\usepackage{multicol}
\parindent=0cm

\theoremstyle{definition}
\newtheorem{theorem}{Теорема}[section]
\newtheorem*{example}{Пример}
\newtheorem{lemma}[theorem]{Лемма}
\newtheorem{definition}{Определение}
\newtheorem{statement}[theorem]{Утверждение}
\renewcommand\qedsymbol{$\blacksquare$}


%Картинки
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{subcaption}

%Математика
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{mathtools}

%Всякое
\usepackage{relsize}
\usepackage{enumerate}
\usepackage[inline]{enumitem}
\usepackage{hyperref}

%Мат команды
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\I}{\mathbb{I}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\D}{\mathbb{D}}
\newcommand{\prob}{\mathbb{P}}

%Оглавление
\title{\textbf{ТВиМС}}\date{}\author{}

\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

\newcommand\defeq{\stackrel{\mathclap{\scalebox{0.6}{def}}}{=}}

\begin{document}

\maketitle
\tableofcontents
\label{toc}
\newpage

\section{Случайная величина}

\begin{definition}
    Случайной величиной $\xi$ называется функция, заданная на множестве $\Omega$, принимающая значения в $\R$.
\end{definition}

    Задать случайную величину, значит указать все ее реализации и соответственные вероятности.

\begin{definition}
    Индикатором события $A$ называется случайная величина: $$\I(A)\sim \left(\genfrac{}{}{0pt}{0}{0}{1-\prob(A)}\,\,\, \genfrac{}{}{0pt}{0}{1}{\prob(A)} \right)$$
\end{definition}

\begin{definition}
    Законом распределения случайной величины называется некоторое правило, позволяющее однозначно определить значение вероятности по значению случайной величины.
\end{definition}

    \subsection{Числовые характеристики случайных величин}

\begin{definition}
    Математическим ожиданием дискретной случайной величины, если оно существует, называется число: 
    $$\E (\xi)=\sum_{i=1}^{n}\omega_i\cdot \prob(\xi=\omega_i)$$
\end{definition}

\begin{definition}
    Дисперсией случайной величины называется $\D(\xi)=\E(\xi-\E(\xi))^2$.
\end{definition}

\begin{theorem}
    $\E(a\xi+b\eta+c)=a\E(\xi)+b\E(\xi)+c;\;a,b,c\in \R$
\end{theorem}

\begin{proof}
    \begin{align*}
        &\E(a\xi+b\eta+c)=\\
        =&\sum_{i=1}^n \widehat{\omega}_i\cdot\prob(a\xi+b\eta+c=\widehat{\omega}_i)=\\
        =&c+\sum_{i=1}^n \widehat{\omega}_i^c\cdot\prob(a\xi+b\eta=\widehat{\omega}_i^c)=\\
        =&c+\sum_{i=1}^n \omega_i^\xi\cdot \prob(a\xi=\omega_i^\xi)+\sum_{i=1}^n \omega_i^\eta\cdot\prob(b\eta=\omega_i^\eta)=\\            =&c+a\E(\xi)+b\E(\eta)
    \end{align*}
\end{proof}

\begin{theorem}
    Дисперсия случайной величины $\xi$ может быть вычислена, как $\D(\xi)=\E(\xi^2)-(\E(\xi))^2$
\end{theorem}

\begin{proof}
    \begin{align*}
        &\D(\xi)=\E(\xi-\E(\xi))^2=\\
        =&\E(\xi^2-2\xi\E(\xi)+(\E(\xi))^2)=\\
        =&\E(\xi^2)-2(\E(\xi))^2+(\E(\xi))^2=\\
        =&\E(\xi^2)-(\E(\xi))^2
    \end{align*}
\end{proof}

\begin{definition}
    Стандартным отклонением случайной величины $\xi$ называется $\sigma(\xi)=\sqrt{\D(\xi)}$.
\end{definition}

    \subsubsection{Распределение Бернулли}

\begin{definition}
    Случайная величина $\xi$  распределена по Бернулли, если ее распределение суть индикатор.
    $$Ber(p)\sim \left(\genfrac{}{}{0pt}{0}{0}{1-p} \,\,\, \genfrac{}{}{0pt}{0}{1}{p} \right)$$
\end{definition}

    \subsubsection{Биномиальное распределение}

\begin{definition}
    Случайная величина $\xi$ распределена биномиально, если она моделирует схему испытаний  Бернулли или является суммой бернулиевых случайных величин.
    $$B(p,\,n)\sim \left( \genfrac{}{}{0pt}{0}{0}{(1-p)^n} \,\,\, \genfrac{}{}{0pt}{0}{\cdots}{\cdots} \,\,\, \genfrac{}{}{0pt}{0}{k}{C_n^kp^k(1-p)^{n-k}} \,\,\, \genfrac{}{}{0pt}{0}{\cdots}{\cdots} \,\,\, \genfrac{}{}{0pt}{0}{n}{p^n} \right)$$
\end{definition}

\begin{theorem}
    Математическое ожидание биномиально распределенной случайной величины $\xi$ может быть вычислено, как $\E(\xi)=np$.
\end{theorem}

\begin{proof}
    \begin{align*}
        &\E(\xi) = C_n^1pq^{n-1} + 2C_n^2p^2q^{n-2} + \ldots + kC_n^kp^kq^{n-k} + \ldots + nC_n^np^n = \\
        =& np \cdot (C_{n-1}^0q^{n-1} + C_{n-1}^1pq^{n-2}+\ldots + C_{n-1}^{k-1}p^{k-1}q^{n-k} + \ldots + C_{n-1}^{n-1}p^{n-1})=\\
        =& np \cdot (q+p)^{n-1}=\\
        =& np
    \end{align*}
\end{proof}

\begin{theorem}
    Дисперсия независимых случайных величин линейна: $\D(\xi+\eta)=\D(\xi)+\D(\eta)$
\end{theorem}

\begin{lemma}
    Дисперсия биномиально распределенной случайной величины $\xi$ может быть вычислена, как $\D(\xi)=npq$.
\end{lemma}

\begin{proof}
    Пусть $\eta$ -- число успехов в одном испытании Бернули. Тогда:
    $$\eta \sim B(p,\,1) \sim \left(\genfrac{}{}{0pt}{0}{0}{q} \,\,\, \genfrac{}{}{0pt}{0}{1}{p}\right)$$
    В таком случае $\D(\eta)=\E(\eta^2)-(\E(\eta))^2=p-p^2=pq$. Тогда по теореме 1.4:
    $$\D(\xi)=\sum_{i=1}^{n}\D(\xi_i)=pq \cdot n = npq$$
\end{proof}

\subsubsection{Геометрическое распределение}

\begin{definition}
    Случайная величина $\xi$ распределена геометрически, если она моделирует схему испытаний до первого успеха с вероятностью $p$.
    $$Geom(p) \sim \left( \genfrac{}{}{0pt}{0}{1}{p} \,\,\, \genfrac{}{}{0pt}{0}{2}{qp} \,\,\, \genfrac{}{}{0pt}{0}{\cdots}{\cdots} \,\,\, \,\,\, \genfrac{}{}{0pt}{0}{n}{q^{n-1}p} \,\,\, \genfrac{}{}{0pt}{0}{\cdots}{\cdots}\right)$$
\end{definition}

\begin{lemma}
    Математическое ожидание геометрически распределенной случайной величины $\xi$ может быть вычислено, как $\E(\xi)=\dfrac{1}{p}$.
\end{lemma}

\begin{proof}
    \begin{align*}
        &\E(\xi)=p+2qp+2q^2p+\ldots+kq^{k-1}p+\ldots=\\
        =&(p+qp+q^2p+\ldots+q^{k-1}p+\ldots)+(qp+2q^2p+\ldots+(k-1)q^{k-1}p+\ldots)=\\
        =&\frac{p}{1-q}+q(p+2pq+\ldots+(k-1)q^{k-2}p+\ldots)\\\\
        &\E(\xi)=1+q\E(\xi)\\
        &\E(\xi)(1-q)=1\\
        &\E(\xi)=\frac{1}{p}
    \end{align*}
\end{proof}

\begin{lemma}
    Дисперсия геометрически распределенной случайной величины $\xi$ может быть вычислена, как $\D(\xi)=\dfrac{q}{p^2}$.
\end{lemma}

\begin{proof}
    \begin{align*}
        &\D(\xi)=\E(\xi^2)-(\E(\xi))^2\\\\
        &\E(\xi^2)=p+2qp+9q^2p+\ldots+k^2q^{k-1}p+\ldots=\\
        =&p+qp+3qp+4q^2p+5q^2p+\ldots=\\
        =&(qp+4q^2p+\ldots)+(p+3qp+5q^2p+\ldots)\\\\
        &\E(\xi^2)=q\E(\xi^2)+\E(2\xi-1)=\\
        =&(1-p)\E(\xi^2)+\frac{2}{p}-1=\frac{2-p}{p^2}\\\\
        &\D(\xi)=\frac{2-p}{p^2}-\frac{1}{p^2}=\frac{q}{p^2}
    \end{align*}
\end{proof}

\subsubsection{Гипергеометрическое распределение}
\begin{definition}
    Случайная величина $\xi$ распределена гипергеометрически, если она моделирует выбор $n$ элементов из множества мощности $N$ с $K$ помеченными и является числом помеченных в выборке.
\end{definition}
$$\xi \sim HG(N,\,K,\,n)$$
$$\prob(\xi=k)=\frac{C_K^k\cdot C_{N-K}^{n-k}}{C_N^n}$$

\begin{statement}
    Математическое ожидание гипергеометрически распределенной случайной величины $\xi$ может быть вычислено, как $\E(\xi)=\dfrac{n\cdot K}{N}$.
\end{statement}

\begin{proof}
    \begin{align*}
    &\xi = \I(A_1)+\I(A_2)+\ldots+\I(A_n),\, \text{где}\, A_i=\{i\text{-ый элемент выборки помечен}\}\\
    &\I(A_i)\sim \left(\genfrac{}{}{0pt}{0}{0}{1-\frac{K}{N}} \,\,\, \genfrac{}{}{0pt}{0}{1}{\frac{K}{N}} \right)\\
    &\E(\xi)=\sum_{i=1}^n \E(\I(A_i))=n\cdot \frac{K}{N}
\end{align*}
\end{proof}

\subsubsection{Распределение Паскаля}

\begin{definition}
    Случайная величина $\xi$ распределена по Паскалю, если она моделирует испытания до первых $k$ успехов.
\end{definition}

\begin{definition}
    $$\xi \sim NB(p,\,k)\text{, если }\xi=\sum_{i=1}^k\eta_i:\,\forall i \in \{1,\,2,\,\ldots\,,\,k\}:\,\eta_i\sim Geom(p)$$
    $$\prob(\xi=n)=C_{n-1}^{k-1}p^kq^{n-k}$$
\end{definition}

\begin{statement}
    Математическое ожидание случайной величины $\xi$, распределенной по Паскалю, может быть вычислено, как $\E(\xi)=\dfrac{k}{p}$.
\end{statement}
\begin{proof}
    Поскольку математическое ожидание линейно: 
    $$\E(\xi)=\sum_{i=1}^{k}\E(\xi_i)=\frac{1}{p}\cdot k =\frac{k}{p}$$
\end{proof}

\section{Ковариация}

\begin{definition}
    Пусть $\xi$ и $\eta$ -- случайные величины, тогда ковариацией называется:
    $$cov(\xi;\,\eta)=\E((\xi-\E(\xi))(\eta-\E(\eta)))$$
\end{definition}
\begin{theorem}
    Для $cov(\xi;\,\eta)$ выполняются свойства:
    \begin{align*}
        1.\,\,&cov(\xi;\,\xi)\geq0\\
        2.\,\,&cov(\xi;\,\eta)=cov(\eta;\,\xi)\\
        3.\,\,&cov(\lambda \xi;\,\eta)=\lambda\cdot cov(\xi;\,\eta)\\
        4.\,\,&cov(\xi_1+\xi_2;\,\eta)=cov(\xi_1;\,\eta)+cov(\xi_2;\,\eta)\\
        5.\,\,&cov(\xi;\,\eta)\leq \D(\xi)\cdot\D(\eta)
    \end{align*}
\end{theorem}
\begin{theorem}
    $$cov(\xi;\,\eta)=\E(\xi\cdot\eta)-\E(\xi)\cdot\E(\eta)$$
\end{theorem}
\begin{proof}
    \begin{align*}
        &\E((\xi-\E(\xi))(\eta-\E(\eta)))=\\
        =&\E(\xi\cdot\eta-\xi\E(\eta)-\eta\E(\xi)+\E(\xi)\cdot\E(\eta))=\\
        =&\E(\xi\cdot\eta)-\E(\xi\E(\eta))-\E(\eta\E(\xi))+\E(\xi)\cdot\E(\eta)=\\
        =&\E(\xi\cdot\eta)-\E(\xi)\cdot\E(\eta)
    \end{align*}
\end{proof}
\begin{theorem}
    $$\D(\xi+\eta)=\D(\xi)+\D(\eta)+2\cdot cov(\xi;\,\eta)$$
\end{theorem}
\section{Корреляция}

\begin{definition}
    Пусть $\xi$ и $\eta$ -- случайные величины: $\D(\xi)\neq0,\,\D(\eta)\neq0,\,cov(\xi;\,\eta)$ определена корректно. Тогда коэффициентом корреляции $\xi$ и $\eta$ называется:
    $$corr(\xi;\,\eta)=r_{\xi\eta}=\frac{cov(\xi;\,\eta)}{\sigma(\xi)\cdot\sigma(\eta)}$$
    Свойства:
    \begin{align*}
        1.\,\,&|r_{\xi\eta}|\leq 1\\
        2.\,\,&|r_{\xi\eta}|=1\Longleftrightarrow \exists\, k\neq 0,\,b:\,\eta=k\xi+b\text{ (почти наверное).}
    \end{align*}
\end{definition}
\section{Мера Жордана}
\begin{definition}
    $A$ измеримо по Жордану, если $\mu^j(A)=\mu_j(A)$, где $\mu^j(A)=\inf\{\mu(\delta):\,A\subset \delta\}$, $\mu_j(A)=\sup\{\mu(\delta):\,\delta \subset A\}$.
\end{definition}
\begin{definition}
    Пусть $A\subset \Omega$, тогда $\prob(x\in A)=\dfrac{\mu(A)}{\mu(\Omega)}$.
\end{definition}

\section{Распределение Пуассона}
\begin{theorem}[Теорема Пуассона]
    Пусть $n\to\infty$, $p\to 0$, $np\to \lambda$, $\lambda=\text{const}$, тогда если $\xi$ -- количество успехов в серии испытаний Бернулли, то она распределена по Пуассону:
    $$\xi \sim P(\lambda):\,\,\prob(\xi=k)=\dfrac{\lambda^k}{k!}e^{-\lambda}$$
\end{theorem}
\begin{proof}
    \begin{align*}
        &P(\xi=k)=C_n^kp^kq^{n-k}\to\\
        \to&\dfrac{n!}{(n-k)!\cdot k!}\cdot p^kq^{n-k}\to\\
        \to&\dfrac{p^k}{k!\cdot q^k}\cdot \dfrac{n!}{(n-k)!}\cdot q^n\to\\
        \to&\dfrac{p^kq^n}{k!\cdot q^k}\cdot n\cdot(n-1)\cdot(n-2)\cdot\ldots\cdot(n-k+1)\to\\
        \to&\dfrac{p^kq^nn^k}{k!\cdot q^k}\cdot 1\cdot\left(1-\dfrac{1}{n}\right)\cdot\left(1-\dfrac{2}{n}\right)\cdot\ldots\cdot\left(1-\dfrac{k-1}{n}\right)\to
    \end{align*}
    \begin{align*}
        \to&\dfrac{\lambda^k\cdot q^n}{k!\cdot q^k}\cdot\left(1-\dfrac{1}{n}\right)\cdot\left(1-\dfrac{2}{n}\right)\cdot\ldots\cdot\left(1-\dfrac{k-1}{n}\right)\to\\
        \to&\dfrac{\lambda^k}{k!}q^n
    \end{align*}
    $$\ln q^n= n\cdot \ln(1-p)\to -np\to-\lambda \Longrightarrow \dfrac{\lambda^k}{k!}q^n = \dfrac{\lambda^k}{k!}e^{-\lambda}$$
\end{proof}
\begin{theorem}
    $$\lim_{n\to\infty}\sum_{i=0}^n\dfrac{x^i}{i!}=e^x,\,\,x\in \R$$
\end{theorem}
\begin{theorem}
    Пусть $\xi\sim P(\lambda)$. Тогда $\E(\xi)=\D(\xi)=\lambda$.
\end{theorem}
\begin{proof}
    $$\E(\xi)=\sum_{k=0}^{\infty}k\dfrac{\lambda^k}{k!}e^{-\lambda}=e^{-\lambda}\sum_{k=0}^{\infty}\dfrac{\lambda^k}{(k-1)!}=e^{-\lambda}\cdot\lambda\sum_{k=0}^{\infty}\dfrac{\lambda^{k-1}}{(k-1)!}=e^{-\lambda}\cdot\lambda\cdot e^\lambda=\lambda$$
\end{proof}
\begin{lemma}
    Пусть $\xi\sim P(\lambda_\xi)$, $\eta\sim P(\lambda_\eta)$, $\xi$ и $\eta$ независимы. Тогда $(\xi+\eta)\sim P(\lambda_\xi+\lambda_\eta)$.
\end{lemma}
\begin{proof}
    \begin{align*}
        &\prob(\xi+\eta=n)=\\
        =&\sum_{i=0}^{n}\prob(\xi=i)\cdot\prob(\eta=n-i)=\\
        =&\sum_{i=0}^{n}\dfrac{\lambda_\xi^i}{i!}\cdot e^{-\lambda_\xi}\cdot \dfrac{\lambda_\eta^{n-i}}{(n-i)!}\cdot e^{-\lambda_\eta}=\\
        =&e^{-(\lambda_\xi+\lambda_\eta)}\sum_{i=0}^{n}\dfrac{\lambda_\xi^i\cdot\lambda_\eta^{n-i}}{i!\cdot(n-i)!}\cdot \dfrac{n!}{n!}=\\
        =&\dfrac{e^{-(\lambda_\xi+\lambda_\eta)}}{n!}\sum_{i=0}^{n}C_n^i\lambda_\xi^i\lambda_\eta^{n-i}=\\
        =&e^{-(\lambda_\xi+\lambda_\eta)}\cdot \dfrac{(\lambda_\xi+\lambda_\eta)^n}{n!}
    \end{align*}
\end{proof}

\section{Ветвящиеся процессы}

\subsection{Цепи Маркова}

\begin{definition}
    Последовательность случайных величин $\xi_0,\,\xi_1,\,\ldots\,,\,\xi_n$ называется Цепью Маркова, если 
    $$\forall n,\,i_0,\,i_1,\,\ldots\,,\,i_n:\,\,\prob(\xi_{n-1}=x_{i_{n-1}},\,\ldots\,,\,\xi_0=x_{i_{0}})$$
    верно, что:
    $$\prob(\xi_{n}=x_{i_{n}}\,|\,\xi_{n-1}=x_{i_{n-1}},\,\ldots\,,\,\xi_0=x_{i_{0}})=\prob(\xi_{n}=x_{i_{n}}\,|\,\xi_{n-1}=x_{i_{n-1}})$$
\end{definition}
\begin{definition}
    Цепь Маркова называется однородной, если:
    $$\forall i,\,j:\,\,\prob(\xi_n=x_j\,|\,\xi_{n-1}=x_i)=p_{i,j}\text{ не зависит от }n.$$
\end{definition}
\begin{definition}
    Матрица $A=(a_{i,j})$ называется стохастической, если:
    $$\forall i,\,j:\,\,a_{i,j}\in [0;\,1],\,\,\sum_{i}(a_{i,j})=1$$
\end{definition}
\begin{definition}
    Матрица $\pi=(p_{i,j})$ называется матрицей переходных вероятностей.
\end{definition}
\begin{theorem}
    Пусть $p^{(0)}=(p^{(0)}_1,\,p^{(0)}_2,\,\ldots\,,\,p^{(0)}_n)$ и $p^{(k)}=(p^{(k)}_1,\,p^{(k)}_2,\,\ldots\,,\,p^{(k)}_n)$ -- начальное распределение и распределение на $k$-ом шаге соответственно вероятностей Марковской цепи, где $p^{(k)}_i=\prob(\xi_k=x_i)$. Тогда:
    $$p^{(k)}=p^{(0)}\cdot\pi^k$$
\end{theorem}
\subsubsection{Классификация состояний Марковских цепей}
\begin{definition}
    Состояние $x_j$ достижимо из $x_i$, если:
    $$\exists\,k:\,\,P^k_{ij}=\prob(\xi_{m+k}=x_j\,|\,\xi_m=x_i)>0$$
\end{definition}
\begin{definition}
    Состояния называются сообщающимися, если они достижимы друг для друга.
\end{definition}
\begin{definition}
    Состояние $x_i$ называется несущественным, если существует такое состояние $x_j$, что $x_j$ достижимо из $x_i$, но $x_i$ недостижимо из $x_j$.
\end{definition}
\begin{definition}
    Состояние $x_i$ называется существенным, если существует такое состояние $x_j$, что $x_j$ достижимо из $x_i$ и $x_i$ достижимо из $x_j$.
\end{definition}
\begin{definition}
    Марковская цепь, все состояния которой составляют один класс сообщающихся состояний, называется неразложимой.
\end{definition}
\begin{definition}
    Состояние $x_i$ называется возвратным, если вероятность возвращения в это состояние равна 1.
\end{definition}
\begin{definition}
    Состояние $x_i$ называется невозвратным, если вероятность возвращения в это состояние не равна 1.
\end{definition}
\begin{definition}
    Возвратное состояние $x_i$ называется возвратным положительным, если среднее время возвращения в него конечно.
\end{definition}
\begin{definition}
    Возвратное состояние $x_i$ называется возвратным нулевым, если среднее время возвращения в него бесконечно.
\end{definition}
\begin{definition}
    Состояние $x_i$ называется периодическим, если $\NOD\{k:\,\,P^{(k)}_{ii}>0\}=d>1$, где $d$ -- период состояния.
\end{definition}
\subsubsection{Эргодичность}
\begin{definition}
    Марковская цепь называется эргодической, если:
    $$\forall i,\,j:\,\,\exists\lim_{k\to\infty}P^{(k)}_{ij}=p_{ij}>0,\,\,\sum_{j}p_j=1$$
\end{definition}
\begin{theorem}[Критерий эргодичности]
    Марковская цепь эргодична, если:
    $$\exists\,k:\,\,\forall i,\,j:\,\,P^{(k)}_{ij}>0$$
\end{theorem}

\subsubsection{Процесс Гальтона-Ватсона}

\begin{definition}
    Пусть $p_0,\,p_1,\,\ldots\,,\,p_m:\,p_m\geq 0;\,p_0+p_1+\ldots+p_m=1$ – начальное распределение. Пусть для $i\geq 2$ определено: $$p_i^{*k}=\sum_{i_1+i_2+\ldots+i_k=i}p_{i_1}\cdot p_{i_2}\cdot\ldots\cdot p_{i_k}$$
    Процесс Гальтона-Ватсона есть марковская цепь $Z(n),\, n\in \N_0$ с начальным распределением $P_0(k)=\prob(Z(0)=k)$ и переходными вероятностями:
    $$P_{ij}=\prob(Z(n+1)=j\,|\,Z(n)=i)=\begin{cases}
        p_j^{*i},\text{ если }i\geq 1,\,j\geq 0\\
        \delta_{0j},\text{ если }i\geq 0,\,j\geq 0
    \end{cases}$$
    Если не оговорено иного, $P_0(1)=\prob(Z(0)=1)=1;\,\,P_0(k)=0,\,\,k\neq1$.
\end{definition}
\begin{example}[Деление клетки 1]\label{Деление клетки 1}
    Рассмотрим популяцию частиц. Пусть после каждой единицы времени частица либо умирает, либо делится на двое. При этом пусть в начале мы имели только одну частицу, то есть $Z(0)=1$. Рассмотрим случайную величину $\xi_i^{(n)}$ – число потомков $i$-й частицы $n$-го поколения:
    $$Z(n+1)=\xi_1^{(n)}+\xi_2^{(n)}+\ldots+\xi_{Z(n)}^{(n)},\,\,n\geq0$$
    Заметим, что можно также фиксировать не число частиц в момент времени $n$, а число частиц первого поколения:
    $$Z(n+1)=Z_1(n)+Z_2(n)+\ldots+Z_{Z(1)}(n)$$
    Таким образом для независимых $\xi_i^{(n)}$ верно:
    $$\xi_1^{(n)}+\xi_2^{(n)}+\ldots+\xi_{Z(n)}^{(n)}\defeq Z(n+1)=Z_1(n)+Z_2(n)+\ldots+Z_{Z(1)}(n)$$
    Далее смотреть в примере \ref{Деление клетки 2}.
\end{example}

\subsection{Тождество Вальда}

\begin{theorem}
    Пусть $\xi_0,\,\xi_1,\,\ldots$ – независимые одинаково распределенные случайные величины. Пусть $\tau$ – случайный момент времени, не зависящий от $(\xi_i)$. Пусть $S_n=\xi_0+\xi_1+\ldots+\xi_n$. Тогда:
    $$\E(S_\tau)=\E(\xi)\cdot\E(\tau)$$ 
\end{theorem}
\begin{proof}
    $$\sum_{k=1}^{\infty}\prob(\tau\geq k)=\sum_{k=1}^{\infty}\sum_{n=1}^{k}\prob(\tau=n)=\sum_{n=1}^{\infty}\sum_{k=1}^{n}\prob(\tau=n)=\sum_{n=1}^{\infty}n\cdot\prob(\tau=n)=\E(\tau)$$
    $$\E(S_\tau)=\sum_{n=1}^{\infty}\E(S_\tau;\,\tau=n)=\sum_{n=1}^{\infty}\E(\xi_1+\xi_2\ldots+\xi_n;\,\tau=n)=\sum_{n=1}^{\infty}\sum_{k=1}^{n}\E(\xi_k;\,\tau=n)=$$
    $$=\sum_{k=1}^{\infty}\sum_{n=k}^{\infty}\E(\xi_k;\,\tau=n)=\sum_{k=1}^{\infty}\E(\xi_k;\,\tau\geq k)=\sum_{k=i}^{\infty}\E(\xi_k)\cdot\E(\tau\geq k)=\E(\xi)\cdot\E(\tau)$$
\end{proof}

\section{Производящие функции}

\begin{definition}
    Производящей функцией произвольной последовательности $(a_n)$ называется выражение вида:
    $$a_0+a_1z+a_2z^2+\ldots=\sum_{i=0}^{\infty}a_iz^i$$
\end{definition}

\subsection{Операции с производящими функциями}

\begin{definition}
    Суммой производящих функций $A(z)=a_0+a_1z+a_2z^2+\ldots$ и $B(z)=b_0+b_1z+b_2z^2+\ldots$ называется производящая функция:
    $$A(z)+B(z)=(a_0+b_0)+(a_1+b_1)z+(a_2+b_2)z^2+\ldots$$
\end{definition}
\begin{definition}
    Произведением производящих функций $A(z)=a_0+a_1z+a_2z^2+\ldots$ и $B(z)=b_0+b_1z+b_2z^2+\ldots$ называется производящая функция:
    $$A(z)\cdot B(z)=a_0b_0+(a_0b_1+a_1b_0)z+(a_0b_2+a_1b_1+a_2b_0)z^2+\ldots$$
\end{definition}
\begin{definition}
    Пусть $A(z)=a_0+a_1z+a_2z^2+\ldots$; $B(t)=b_0+b_1t+b_2t^2+\ldots;\,b_0=0$ – производящие функции. Подстановкой производящей функции $B$ в производящую функцию $A$ будет называться производящая функция:
    $$A(B(t))=a_0+a_1b_1t+(a_1b_2+a_2b_1^2)t^2+(a_1b_3+2a_2b_1b_2+a_3b_1^3)t^3+\ldots$$
\end{definition}
\begin{theorem}
    Пусть $B(t)=b_0+b_1t+b_2t^2+\ldots;\,b_0=0;\,b_1\neq 0$ – производящая функция. Тогда существуют единственные такие функции $A(z)=a_0+a_1z+a_2z^2+\ldots;\,a_0=0$ и $C(u)=c_0+c_1u+c_2u^2=\ldots;\,c_0=0$, что $A(B(t))=t$ и $B(C(u))=u.$ Функция $A$ называется левой обратной, а функция $C$ – правой обратной к функции $B$.
\end{theorem}
\begin{proof}
    Рассмотрим левую обратную функцию:
    $$A(B(t))=a_1b_1t+(a_1b_2+a_2b_1^2)t^2+(a_1b_3+2a_2b_1b_2+a_3b_1^3)t^3+\ldots=t$$
    Чтобы равенство выполнялось, коэффициент при $t$ должен равняться 1, а коэффициенты при $t^n,\,n\geq 2$ должны равняться 0. Отсюда $a_1b_1=1\Longrightarrow a_1=\dfrac{1}{b_1}$. Пусть аналогично определены коэффициенты $a_1,\,a_2,\,\ldots\,,\,a_n$. Тогда коэффициент $a_{n+1}$ будет определяться из условия, что многочлен $a_{n+1}b^{n+1}_1+\ldots$ от $a_1,\,a_2,\,\ldots\,,\,a_n,\,a_{n+1}$ и $b_1,\,b_2,\,\ldots\,,\,b_n,\,b_{n+1}$, являющийся коэффициентом при $t^{n+1}$, будет равен нулю. Поскольку $b_1\neq 0$ по условию, получаем уравнение от $a_{n+1}$ с единственным корнем. То есть мы однозначно можем задать такие коэффициенты $a_1,\,a_2,\,\ldots$, чтобы $A(B(t))=t$.\bigskip
    
    Доказательство для правой обратной функции аналогично.
\end{proof}
\begin{definition}
    Производящая функция называется рациональной, если ее можно представить в виде $\dfrac{P(x)}{Q(x)}$, где $P(x)$ и $Q(x)$ – многочлены.
\end{definition}

\subsection{Производящие функции вероятности}

\begin{definition}
    Производящей функцией $\varphi_\xi$ случайной величины $\xi$ называется производящая функция последовательности $\left(\prob(\xi=n)\right)^\infty_{n=0}$:
    $$\varphi_\xi(z)=\sum_{n=0}^{\infty}z^n\prob(\xi=n)=\E(z^\xi)$$
    Причем $\varphi_\xi(1)=1$ как сумма вероятностей. Рассмотрим производную данной функции:
    \begin{multicols}{2}
        \centering
        \[\varphi'_\xi(z)=\sum_{n=0}^\infty n\cdot z^{n-1}\prob(\xi=n)\]\\
        \[\varphi'_\xi(1)=\sum_{n=0}^\infty n\cdot \prob(\xi=n)=\E(\xi)\]
    \end{multicols}
\end{definition}
\begin{definition}
    Итерацией производящей функции случайной величины порядка $n$ называется композиция, строящаяся рекуррентно:
    \begin{multicols}{3}
        \centering
        $\varphi_0(z)=z$\\
        $\varphi_1(z)=\varphi(z)$\\
        $\varphi_{n+1}(z)=\varphi_n(\varphi(z))$
    \end{multicols}
\end{definition}
\begin{definition}
    Пусть $\xi_i,\,\,i\in\{1,\,\,2,\ldots,\,\,n\}$ – независимые случайные величины, тогда:
    $$\varphi_{\xi_1+\xi_2+\ldots+\xi_n}(z)=\varphi_{\xi_1}\cdot\varphi_{\xi_2}\cdot\ldots\cdot\varphi_{\xi_n}$$
\end{definition}
\begin{example}[Деление клетки 2]\label{Деление клетки 2}
    Продолжим рассмотрение примера \ref{Деление клетки 1}.
\end{example}

\end{document}