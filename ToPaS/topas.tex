%Формат файла
\documentclass[12pt]{article} 
\usepackage[paperheight=297mm,
   paperwidth=210mm,
   top=20mm,
   bottom=20mm,
   left=15mm,
   right=15mm]{geometry}


%Текст
\usepackage[fontsize=12pt]{fontsize}
\usepackage[russian]{babel}
\usepackage{color}
\usepackage{transparent}
\usepackage{amsthm}
\parindent=0cm

\theoremstyle{definition}
\newtheorem{theorem}{Теорема}[section]
\newtheorem{lemma}[theorem]{Лемма}
\newtheorem{definition}{Определение}
\newtheorem{statement}[theorem]{Утверждение}
\renewcommand\qedsymbol{$\blacksquare$}


%Картинки
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{subcaption}

%Математика
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{mathabx}
\usepackage{amssymb}

%Всякое
\usepackage{relsize}
\usepackage{enumerate}
\usepackage[inline]{enumitem}
\usepackage{hyperref}

%Мат команды
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\I}{\mathbb{I}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\D}{\mathbb{D}}
\newcommand{\prob}{\mathbb{P}}

%Оглавление
\title{\textbf{ТВиМС}}\date{}\author{}

\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

\begin{document}

\maketitle
\tableofcontents
\label{toc}
\newpage

\section{Случайная величина}

\begin{definition}
    Случайной величиной $\xi$ называется функция, заданная на множестве $\Omega$, принимающая значения в $\R$.
\end{definition}

    Задать случайную величину, значит указать все ее реализации и соответственные вероятности.

\begin{definition}
    Индикатором события $A$ называется случайная величина $\I(A)\sim \left({0 \atop 1-\prob(A)} {1 \atop \prob(A)} \right)$.
\end{definition}

\begin{definition}
    Законом распределения случайной величины называется некоторое правило, позволяющее однозначно определить значение вероятности по значению случайной величины.
\end{definition}

    \subsection{Числовые характеристики случайных величин}

\begin{definition}
    Математическим ожиданием дискретной случайной величины, если оно существует, называется число: 
    $$\E (\xi)=\sum_{i=1}^{n}\omega_i\cdot \prob(\xi=\omega_i)$$
\end{definition}

\begin{definition}
    Дисперсией случайной величины называется $\D(\xi)=\E(\xi-\E(\xi))^2$.
\end{definition}

\begin{theorem}
    $\E(a\xi+b\eta+c)=a\E(\xi)+b\E(\xi)+c;\;a,b,c\in \R$
\end{theorem}

\begin{proof}
    \begin{align*}
        &\E(a\xi+b\eta+c)=\\
        =&\sum_{i=1}^n \widehat{\omega}_i\cdot\prob(a\xi+b\eta+c=\widehat{\omega}_i)=\\
        =&c+\sum_{i=1}^n \widehat{\omega}_i^c\cdot\prob(a\xi+b\eta=\widehat{\omega}_i^c)=\\
        =&c+\sum_{i=1}^n \omega_i^\xi\cdot \prob(a\xi=\omega_i^\xi)+\sum_{i=1}^n \omega_i^\eta\cdot\prob(b\eta=\omega_i^\eta)=\\            =&c+a\E(\xi)+b\E(\eta)
    \end{align*}
\end{proof}

\begin{theorem}
    Дисперсия случайной величины $\xi$ может быть вычислена, как $\D(\xi)=\E(\xi^2)-(\E(\xi))^2$
\end{theorem}

\begin{proof}
    \begin{align*}
        &\D(\xi)=\E(\xi-\E(\xi))^2=\\
        =&\E(\xi^2-2\xi\E(\xi)+(\E(\xi))^2)=\\
        =&\E(\xi^2)-2(\E(\xi))^2+(\E(\xi))^2=\\
        =&\E(\xi^2)-(\E(\xi))^2
    \end{align*}
\end{proof}

\begin{definition}
    Стандартным отклонением случайной величины $\xi$ называется $\sigma(\xi)=\sqrt{\D(\xi)}$.
\end{definition}

    \subsubsection{Распределение Бернулли}

\begin{definition}
    Случайная величина $\xi$  распределена по Бернулли, если ее распределение суть индикатор.
    $$Ber(p)\sim \left({0 \atop 1-p} \,\ \, {1 \atop p} \right)$$
\end{definition}

    \subsubsection{Биномиальное распределение}

\begin{definition}
    Случайная величина $\xi$ распределена биномиально, если она моделирует схему испытаний  Бернулли или является суммой бернулиевых случайных величин.
    $$B(p,\,n)\sim \left( {0 \atop (1-p)^n} \,\,\, {... \atop ...} \,\,\, {k \atop C_n^kp^k(1-p)^{n-k}} \,\,\, {... \atop ...} \,\,\, {n \atop p^n} \right)$$
\end{definition}

\begin{theorem}
    Математическое ожидание биномиально распределенной случайной величины $\xi$ может быть вычислено, как $\E(\xi)=np$.
\end{theorem}

\begin{proof}
    \begin{align*}
        &\E(\xi) = C_n^1pq^{n-1} + 2C_n^2p^2q^{n-2} + \ldots + kC_n^kp^kq^{n-k} + \ldots + nC_n^np^n = \\
        =& np \cdot (C_{n-1}^0q^{n-1} + C_{n-1}^1pq^{n-2}+\ldots + C_{n-1}^{k-1}p^{k-1}q^{n-k} + \ldots + C_{n-1}^{n-1}p^{n-1})=\\
        =& np \cdot (q+p)^{n-1}=\\
        =& np
    \end{align*}
\end{proof}

\begin{theorem}
    Дисперсия независимых случайных величин линейна: $\D(\xi+\eta)=\D(\xi)+\D(\eta)$
\end{theorem}

\begin{lemma}
    Дисперсия биномиально распределенной случайной величины $\xi$ может быть вычислена, как $\D(\xi)=npq$.
\end{lemma}

\begin{proof}
    Пусть $\eta$ -- число успехов в одном испытании Бернули. Тогда:
    $$\eta \sim B(p,\,1) \sim \left({0 \atop q} \,\,\, {1 \atop p}\right)$$
    В таком случае $\D(\eta)=\E(\eta^2)-(\E(\eta))^2=p-p^2=pq$. Тогда по теореме 1.4:
    $$\D(\xi)=\sum_{i=1}^{n}\D(\xi_i)=pq \cdot n = npq$$
\end{proof}

\subsubsection{Геометрическое распределение}

\begin{definition}
    Случайная величина $\xi$ распределена геометрически, если она моделирует схему испытаний до первого успеха с вероятностью $p$.
    $$Geom(p) \sim \left( {1 \atop p} \,\,\, {2 \atop qp} \,\,\, {... \atop ...} \,\,\, \,\,\, {n \atop q^{n-1}p} \,\,\, {... \atop ...}\right)$$
\end{definition}

\begin{lemma}
    Математическое ожидание геометрически распределенной случайной величины $\xi$ может быть вычислено, как $\E(\xi)=\dfrac{1}{p}$.
\end{lemma}

\begin{proof}
    \begin{align*}
        &\E(\xi)=p+2qp+2q^2p+\ldots+kq^{k-1}p+\ldots=\\
        =&(p+qp+q^2p+\ldots+q^{k-1}p+\ldots)+(qp+2q^2p+\ldots+(k-1)q^{k-1}p+\ldots)=\\
        =&\frac{p}{1-q}+q(p+2pq+\ldots+(k-1)q^{k-2}p+\ldots)\\\\
        &\E(\xi)=1+q\E(\xi)\\
        &\E(\xi)(1-q)=1\\
        &\E(\xi)=\frac{1}{p}
    \end{align*}
\end{proof}

\begin{lemma}
    Дисперсия геометрически распределенной случайной величины $\xi$ может быть вычислена, как $\D(\xi)=\dfrac{q}{p^2}$.
\end{lemma}

\begin{proof}
    \begin{align*}
        &\D(\xi)=\E(\xi^2)-(\E(\xi))^2\\\\
        &\E(\xi^2)=p+2qp+9q^2p+\ldots+k^2q^{k-1}p+\ldots=\\
        =&p+qp+3qp+4q^2p+5q^2p+\ldots=\\
        =&(qp+4q^2p+\ldots)+(p+3qp+5q^2p+\ldots)
    \end{align*}
    \begin{align*}
        &\E(\xi^2)=q\E(\xi^2)+\E(2\xi-1)=\\
        =&(1-p)\E(\xi^2)+\frac{2}{p}-1=\\
        =&\frac{2-p}{p^2}\\\\
        &\D(\xi)=\frac{2-p}{p^2}-\frac{1}{p^2}=\\
        =&\frac{q}{p^2}
    \end{align*}
\end{proof}

\subsubsection{Гипергеометрическое распределение}
\begin{definition}
    Случайная величина $\xi$ распределена гипергеометрически, если она моделирует выбор $n$ элементов из множества мощности $N$ с $K$ помеченными и является числом помеченных в выборке.
\end{definition}
$$\xi \sim HG(N,\,K,\,n)$$
$$\prob(\xi=k)=\frac{C_K^k\cdot C_{N-K}^{n-k}}{C_N^n}$$

\begin{statement}
    Математическое ожидание гипергеометрически распределенной случайной величины $\xi$ может быть вычислено, как $\E(\xi)=\dfrac{n\cdot K}{N}$.
\end{statement}

\begin{proof}
    \begin{align*}
    &\xi = \I(A_1)+\I(A_2)+\ldots+\I(A_n),\, \text{где}\, A_i=\{i\text{-ый элемент выборки помечен}\}\\
    &\I(A_i)\sim \left({0 \atop 1-\frac{K}{N}} \,\,\, {1 \atop \frac{K}{N}} \right)\\
    &\E(\xi)=\sum_{i=1}^n \E(\I(A_i))=n\cdot \frac{K}{N}
\end{align*}
\end{proof}

\subsubsection{Распределение Паскаля}

\begin{definition}
    Случайная величина $\xi$ распределена по Паскалю, если она моделирует испытания до первых $k$ успехов.
\end{definition}

\begin{definition}
    $$\xi \sim NB(p,\,k)\text{, если }\xi=\sum_{i=1}^k\eta_i:\,\forall i \in \{1,\,2,\,\ldots,\,k\}:\,\eta_i\sim Geom(p)$$
    $$\prob(\xi=n)=C_{n-1}^{k-1}p^kq^{n-k}$$
\end{definition}

\begin{statement}
    Математическое ожидание случайной величины $\xi$, распределенной по Паскалю, может быть вычислено, как $\E(\xi)=\dfrac{k}{p}$.
\end{statement}
\begin{proof}
    Поскольку математическое ожидание линейно: 
    $$\E(\xi)=\sum_{i=1}^{k}\E(\xi_i)=\frac{1}{p}\cdot k =\frac{k}{p}$$
\end{proof}

\section{Ковариация}

\begin{definition}
    Пусть $\xi$ и $\eta$ -- случайные величины, тогда ковариацией называется:
    $$cov(\xi;\,\eta)=\E((\xi-\E(\xi))(\eta-\E(\eta)))$$
\end{definition}
\begin{theorem}
    Для $cov(\xi;\,\eta)$ выполняются свойства:
    \begin{align*}
        1.\,\,&cov(\xi;\,\xi)\geq0\\
        2.\,\,&cov(\xi;\,\eta)=cov(\eta;\,\xi)\\
        3.\,\,&cov(\lambda \xi;\,\eta)=\lambda\cdot cov(\xi;\,\eta)\\
        4.\,\,&cov(\xi_1+\xi_2;\,\eta)=cov(\xi_1;\,\eta)+cov(\xi_2;\,\eta)\\
        5.\,\,&cov(\xi;\,\eta)\leq \D(\xi)\cdot\D(\eta)
    \end{align*}
\end{theorem}
\begin{theorem}
    $$cov(\xi;\,\eta)=\E(\xi\cdot\eta)-\E(\xi)\cdot\E(\eta)$$
\end{theorem}
\begin{proof}
    \begin{align*}
        &\E((\xi-\E(\xi))(\eta-\E(\eta)))=\\
        =&\E(\xi\cdot\eta-\xi\E(\eta)-\eta\E(\xi)+\E(\xi)\cdot\E(\eta))=\\
        =&\E(\xi\cdot\eta)-\E(\xi\E(\eta))-\E(\eta\E(\xi))+\E(\xi)\cdot\E(\eta)=\\
        =&\E(\xi\cdot\eta)-\E(\xi)\cdot\E(\eta)
    \end{align*}
\end{proof}
\begin{theorem}
    $$\D(\xi+\eta)=\D(\xi)+\D(\eta)+2\cdot cov(\xi;\,\eta)$$
\end{theorem}
\section{Корреляция}

\begin{definition}
    Пусть $\xi$ и $\eta$ -- случайные величины: $\D(\xi)\neq0,\,\D(\eta)\neq0,\,cov(\xi;\,\eta)$ определена корректно. Тогда коэффициентом корреляции $\xi$ и $\eta$ называется:
    $$corr(\xi;\,\eta)=r_{\xi\eta}=\frac{cov(\xi;\,\eta)}{\sigma(\xi)\cdot\sigma(\eta)}$$
    Свойства:
    \begin{align*}
        1.\,\,&|r_{\xi\eta}|\leq 1\\
        2.\,\,&|r_{\xi\eta}|=1\Longleftrightarrow \exists\, k\neq 0,\,b:\,\eta=k\xi+b\text{ (почти наверное).}
    \end{align*}
\end{definition}
\section{Мера Жордана}
\begin{definition}
    $A$ измеримо по Жордану, если $\mu^j(A)=\mu_j(A)$, где $\mu^j(A)=\inf\{\mu(\delta):\,A\subset \delta\}$, $\mu_j(A)=\sup\{\mu(\delta):\,\delta \subset A\}$.
\end{definition}
\begin{definition}
    Пусть $A\subset \Omega$, тогда $\prob(x\in A)=\dfrac{\mu(A)}{\mu(\Omega)}$.
\end{definition}

\section{Распределение Пуассона}
\begin{theorem}[Теорема Пуассона]
    Пусть $n\to\infty$, $p\to 0$, $np\to \lambda$, $\lambda=\text{const}$, тогда если $\xi$ -- количество успехов в серии испытаний Бернулли, то она распределена по Пуассону:
    $$\xi \sim P(\lambda):\,\,\prob(\xi=k)=\dfrac{\lambda^k}{k!}e^{-\lambda}$$
\end{theorem}
\begin{proof}
    \begin{align*}
        &P(\xi=k)=C_n^kp^kq^{n-k}\to\\
        \to&\dfrac{n!}{(n-k)!\cdot k!}\cdot p^kq^{n-k}\to\\
        \to&\dfrac{p^k}{k!\cdot q^k}\cdot \dfrac{n!}{(n-k)!}\cdot q^n\to\\
        \to&\dfrac{p^kq^n}{k!\cdot q^k}\cdot n\cdot(n-1)\cdot(n-2)\cdot\ldots\cdot(n-k+1)\to\\
        \to&\dfrac{p^kq^nn^k}{k!\cdot q^k}\cdot 1\cdot\left(1-\dfrac{1}{n}\right)\cdot\left(1-\dfrac{2}{n}\right)\cdot\ldots\cdot\left(1-\dfrac{k-1}{n}\right)\to
    \end{align*}
    \begin{align*}
        \to&\dfrac{\lambda^k\cdot q^n}{k!\cdot q^k}\cdot\left(1-\dfrac{1}{n}\right)\cdot\left(1-\dfrac{2}{n}\right)\cdot\ldots\cdot\left(1-\dfrac{k-1}{n}\right)\to\\
        \to&\dfrac{\lambda^k}{k!}q^n
    \end{align*}
    $$\ln q^n= n\cdot \ln(1-p)\to -np\to-\lambda \Longrightarrow \dfrac{\lambda^k}{k!}q^n = \dfrac{\lambda^k}{k!}e^{-\lambda}$$
\end{proof}
\begin{theorem}
    $$\lim_{n\to\infty}\sum_{i=0}^n\dfrac{x^i}{i!}=e^x,\,\,x\in \R$$
\end{theorem}
\begin{theorem}
    Пусть $\xi\sim P(\lambda)$. Тогда $\E(\xi)=\D(\xi)=\lambda$.
\end{theorem}
\begin{proof}
    $$\E(\xi)=\sum_{k=0}^{\infty}k\dfrac{\lambda^k}{k!}e^{-\lambda}=e^{-\lambda}\sum_{k=0}^{\infty}\dfrac{\lambda^k}{(k-1)!}=e^{-\lambda}\cdot\lambda\sum_{k=0}^{\infty}\dfrac{\lambda^{k-1}}{(k-1)!}=e^{-\lambda}\cdot\lambda\cdot e^\lambda=\lambda$$
\end{proof}
\begin{lemma}
    Пусть $\xi\sim P(\lambda_\xi)$, $\eta\sim P(\lambda_\eta)$, $\xi$ и $\eta$ независимы. Тогда $(\xi+\eta)\sim P(\lambda_\xi+\lambda_\eta)$.
\end{lemma}
\begin{proof}
    \begin{align*}
        &\prob(\xi+\eta=n)=\\
        =&\sum_{i=0}^{n}\prob(\xi=i)\cdot\prob(\eta=n-i)=\\
        =&\sum_{i=0}^{n}\dfrac{\lambda_\xi^i}{i!}\cdot e^{-\lambda_\xi}\cdot \dfrac{\lambda_\eta^{n-i}}{(n-i)!}\cdot e^{-\lambda_\eta}=\\
        =&e^{-(\lambda_\xi+\lambda_\eta)}\sum_{i=0}^{n}\dfrac{\lambda_\xi^i\cdot\lambda_\eta^{n-i}}{i!\cdot(n-i)!}\cdot \dfrac{n!}{n!}=\\
        =&\dfrac{e^{-(\lambda_\xi+\lambda_\eta)}}{n!}\sum_{i=0}^{n}C_n^i\lambda_\xi^i\lambda_\eta^{n-i}=\\
        =&e^{-(\lambda_\xi+\lambda_\eta)}\cdot \dfrac{(\lambda_\xi+\lambda_\eta)^n}{n!}
    \end{align*}
\end{proof}
\section{Цепи Маркова}
\begin{definition}
    Последовательность случайных величин $\xi_0,\,\xi_1,\ldots,\,\xi_n$ называется Цепью Маркова, если 
    $$\forall n,\,i_0,\,i_1,\ldots,\,i_n:\,\,\prob(\xi_{n-1}=x_{i_{n-1}},\ldots,\,\xi_0=x_{i_{0}})$$
    верно, что:
    $$\prob(\xi_{n}=x_{i_{n}}\,|\,\xi_{n-1}=x_{i_{n-1}},\ldots,\,\xi_0=x_{i_{0}})=\prob(\xi_{n}=x_{i_{n}}\,|\,\xi_{n-1}=x_{i_{n-1}})$$
\end{definition}
\begin{definition}
    Цепь Маркова называется однородной, если:
    $$\forall i,\,j:\,\,\prob(\xi_n=x_j\,|\,\xi_{n-1}=x_i)=p_{i,j}\text{ не зависит от }n.$$
\end{definition}
\begin{definition}
    Матрица $A=(a_{i,j})$ называется стохастической, если:
    $$\forall i,\,j:\,\,a_{i,j}\in [0;\,1],\,\,\sum_{i}(a_{i,j})=1$$
\end{definition}
\begin{definition}
    Матрица $\pi=(p_{i,j})$ называется матрицей переходных вероятностей.
\end{definition}
\begin{theorem}
    Пусть $p^{(0)}=(p^{(0)}_1,\,p^{(0)}_2,\ldots,\,p^{(0)}_n)$ и $p^{(k)}=(p^{(k)}_1,\,p^{(k)}_2,\ldots,\,p^{(k)}_n)$ -- начальное распределение и распределение на $k$-ом шаге соответственно вероятностей Марковской цепи, где $p^{(k)}_i=\prob(\xi_k=x_i)$. Тогда:
    $$p^{(k)}=p^{(0)}\cdot\pi^k$$
\end{theorem}
\subsection{Классификация состояний Марковских цепей}
\begin{definition}
    Состояние $x_j$ достижимо из $x_i$, если:
    $$\exists\,k:\,\,P^k_{ij}=\prob(\xi_{m+k}=x_j\,|\,\xi_m=x_i)>0$$
\end{definition}
\begin{definition}
    Состояния называются сообщающимися, если они достижимы друг для друга.
\end{definition}
\begin{definition}
    Состояние $x_i$ называется несущественным, если существует такое состояние $x_j$, что $x_j$ достижимо из $x_i$, но $x_i$ недостижимо из $x_j$.
\end{definition}
\begin{definition}
    Состояние $x_i$ называется существенным, если существует такое состояние $x_j$, что $x_j$ достижимо из $x_i$ и $x_i$ достижимо из $x_j$.
\end{definition}
\begin{definition}
    Марковская цепь, все состояния которой составляют один класс сообщающихся состояний, называется неразложимой.
\end{definition}
\begin{definition}
    Состояние $x_i$ называется возвратным, если вероятность возвращения в это состояние равна 1.
\end{definition}
\begin{definition}
    Состояние $x_i$ называется невозвратным, если вероятность возвращения в это состояние не равна 1.
\end{definition}
\begin{definition}
    Возвратное состояние $x_i$ называется возвратным положительным, если среднее время возвращения в него конечно.
\end{definition}
\begin{definition}
    Возвратное состояние $x_i$ называется возвратным нулевым, если среднее время возвращения в него бесконечно.
\end{definition}
\begin{definition}
    Состояние $x_i$ называется периодическим, если $\NOD\{k:\,\,P^{(k)}_{ii}>0\}=d>1$, где $d$ -- период состояния.
\end{definition}
\subsection{Эргодичность}
\begin{definition}
    Марковская цепь называется эргодической, если:
    $$\forall i,\,j:\,\,\exists\lim_{k\to\infty}P^{(k)}_{ij}=p_{ij}>0,\,\,\sum_{j}p_j=1$$
\end{definition}
\begin{theorem}[Критерий эргодичности]
    Марковская цепь эргодична, если:
    $$\exists\,k:\,\,\forall i,\,j:\,\,P^{(k)}_{ij}>0$$
\end{theorem}
\end{document}